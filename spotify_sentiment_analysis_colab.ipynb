{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Spotify Dataset Sentiment Analysis using Na√Øve Bayes\n",
    "\n",
    "This notebook implements sentiment classification using MultinomialNB with comprehensive text preprocessing techniques.\n",
    "\n",
    "**üöÄ Google Colab Ready** - All dependencies will be installed automatically!\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EhsanulHaqueSiam/spotify-review-sentiment/blob/main/spotify_sentiment_analysis_colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß Setup: Install Dependencies (Colab Only)\n",
    "\n",
    "**Note**: This cell installs required packages. Skip if running locally with existing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages for Google Colab\n",
    "import sys\n",
    "\n",
    "# Check if running in Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üîß Installing packages for Google Colab...\")\n",
    "    \n",
    "    # Install packages\n",
    "    !pip install -q kagglehub spacy seaborn\n",
    "    \n",
    "    # Download spaCy English model\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    \n",
    "    print(\"‚úÖ All packages installed successfully!\")\n",
    "else:\n",
    "    print(\"üìù Running locally - assuming dependencies are already installed\")\n",
    "\n",
    "print(\"üéµ Ready to start sentiment analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaggle_setup"
   },
   "source": [
    "## üîë Kaggle API Setup (Required for Dataset)\n",
    "\n",
    "**For Google Colab users**: Use Colab Secrets (recommended), manual credentials, or upload `kaggle.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaggle_auth"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üîë Setting up Kaggle API for Google Colab...\")\n",
    "    \n",
    "    try:\n",
    "        # Option 1: Use Google Colab Secrets (Recommended)\n",
    "        from google.colab import userdata\n",
    "        \n",
    "        print(\"üì± Using Google Colab Secrets...\")\n",
    "        print(\"üí° To set up secrets:\")\n",
    "        print(\"   1. Click the üîë key icon in the left sidebar\")\n",
    "        print(\"   2. Add two secrets:\")\n",
    "        print(\"      - Name: KAGGLE_USERNAME, Value: your_kaggle_username\")\n",
    "        print(\"      - Name: KAGGLE_KEY, Value: your_kaggle_api_key\")\n",
    "        print(\"   3. Enable notebook access for both secrets\")\n",
    "        \n",
    "        # Get credentials from secrets\n",
    "        kaggle_username = userdata.get('KAGGLE_USERNAME')\n",
    "        kaggle_key = userdata.get('KAGGLE_KEY')\n",
    "        \n",
    "        # Set environment variables\n",
    "        os.environ['KAGGLE_USERNAME'] = kaggle_username\n",
    "        os.environ['KAGGLE_KEY'] = kaggle_key\n",
    "        \n",
    "        print(\"‚úÖ Kaggle credentials loaded from secrets!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Secrets method failed: {e}\")\n",
    "        print(\"\\nüîß Fallback options:\")\n",
    "        \n",
    "        # Option 2: Manual environment variables\n",
    "        print(\"\\nüìù Option A: Set credentials manually\")\n",
    "        print(\"Uncomment and fill in the lines below:\")\n",
    "        print(\"# os.environ['KAGGLE_USERNAME'] = 'your_username'\")\n",
    "        print(\"# os.environ['KAGGLE_KEY'] = 'your_api_key'\")\n",
    "        \n",
    "        # Uncomment these lines and add your credentials:\n",
    "        # os.environ['KAGGLE_USERNAME'] = 'your_username'\n",
    "        # os.environ['KAGGLE_KEY'] = 'your_api_key'\n",
    "        \n",
    "        # Option 3: Upload kaggle.json file\n",
    "        print(\"\\nüìÅ Option B: Upload kaggle.json file\")\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            print(\"Click to upload your kaggle.json file:\")\n",
    "            uploaded = files.upload()\n",
    "            \n",
    "            if 'kaggle.json' in uploaded:\n",
    "                !mkdir -p ~/.kaggle\n",
    "                !cp kaggle.json ~/.kaggle/\n",
    "                !chmod 600 ~/.kaggle/kaggle.json\n",
    "                print(\"‚úÖ Kaggle credentials uploaded successfully!\")\n",
    "            else:\n",
    "                print(\"‚ùå kaggle.json not found in uploaded files\")\n",
    "        except Exception as upload_error:\n",
    "            print(f\"‚ùå File upload failed: {upload_error}\")\n",
    "            print(\"Please use manual credentials setup above.\")\n",
    "        \n",
    "else:\n",
    "    print(\"üìù Running locally - using existing Kaggle credentials\")\n",
    "\n",
    "print(\"\\nüí° Get your Kaggle API credentials from: https://www.kaggle.com/settings/account\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task1"
   },
   "source": [
    "## Task 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import basic libraries for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Basic libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task2"
   },
   "source": [
    "## Task 2: Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_dataset"
   },
   "outputs": [],
   "source": [
    "# Import kagglehub for dataset loading\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download the Spotify dataset from Kaggle\n",
    "print(\"Downloading Spotify dataset from Kaggle...\")\n",
    "try:\n",
    "    # Download the dataset files to local directory\n",
    "    path = kagglehub.dataset_download(\"alexandrakim2201/spotify-dataset\")\n",
    "    print(f\"Dataset downloaded to: {path}\")\n",
    "    \n",
    "    # List files in the downloaded directory\n",
    "    files = os.listdir(path)\n",
    "    print(f\"Available files: {files}\")\n",
    "    \n",
    "    # Find the CSV file (should be the main dataset)\n",
    "    csv_files = [f for f in files if f.endswith('.csv')]\n",
    "    if csv_files:\n",
    "        csv_file = csv_files[0]  # Take the first CSV file\n",
    "        file_path = os.path.join(path, csv_file)\n",
    "        print(f\"Loading CSV file: {csv_file}\")\n",
    "        \n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "    else:\n",
    "        print(\"No CSV files found in the dataset\")\n",
    "        # Fallback: try to load any file as CSV\n",
    "        if files:\n",
    "            file_path = os.path.join(path, files[0])\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"Loaded {files[0]} as CSV\")\n",
    "        else:\n",
    "            raise FileNotFoundError(\"No files found in dataset\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error downloading from Kaggle: {e}\")\n",
    "    print(\"Please ensure you have Kaggle API credentials set up.\")\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        print(\"\\nüîß For Google Colab:\")\n",
    "        print(\"1. Upload kaggle.json file in the previous cell\")\n",
    "        print(\"2. Or set KAGGLE_USERNAME and KAGGLE_KEY environment variables\")\n",
    "    \n",
    "    # Create sample data for demonstration if dataset fails to load\n",
    "    print(\"\\n‚ö†Ô∏è Creating sample data for demonstration...\")\n",
    "    sample_data = {\n",
    "        'Review': [\n",
    "            'Great music service, love the playlists!',\n",
    "            'App crashes frequently, very annoying',\n",
    "            'Amazing sound quality and user interface',\n",
    "            'Too expensive for what it offers',\n",
    "            'Perfect for discovering new music'\n",
    "        ],\n",
    "        'label': ['POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE']\n",
    "    }\n",
    "    df = pd.DataFrame(sample_data)\n",
    "    print(\"Sample dataset created for demonstration purposes\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset shape:\", df.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(\"\\nDataset description:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task3"
   },
   "source": [
    "## Task 3: Data Preprocessing and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore_data"
   },
   "outputs": [],
   "source": [
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Explore the target variable (sentiment)\n",
    "# Dataset has 51,473 rows with columns: 'Review' (text) and 'label' (POSITIVE/NEGATIVE)\n",
    "sentiment_column = 'label'  # Sentiment labels: POSITIVE/NEGATIVE\n",
    "text_column = 'Review'  # User review text\n",
    "\n",
    "if sentiment_column in df.columns:\n",
    "    print(\"Sentiment distribution:\")\n",
    "    print(df[sentiment_column].value_counts())\n",
    "    \n",
    "    # Visualize sentiment distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    df[sentiment_column].value_counts().plot(kind='bar')\n",
    "    plt.title('Sentiment Distribution')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Please update the sentiment_column variable with the correct column name\")\n",
    "    print(\"Available columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task4"
   },
   "source": [
    "## Task 4: Text Preprocessing - Initialize Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_preprocessing"
   },
   "outputs": [],
   "source": [
    "# Import text preprocessing libraries\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download required NLTK data\n",
    "print(\"üìö Downloading NLTK data...\")\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "print(\"‚úÖ NLTK data downloaded\")\n",
    "\n",
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print(\"‚úÖ spaCy English model loaded\")\n",
    "except OSError:\n",
    "    print(\"‚ùå spaCy English model not found\")\n",
    "    if IN_COLAB:\n",
    "        print(\"Installing spaCy model...\")\n",
    "        !python -m spacy download en_core_web_sm\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        print(\"‚úÖ spaCy English model installed and loaded\")\n",
    "    else:\n",
    "        print(\"Please install spaCy English model: python -m spacy download en_core_web_sm\")\n",
    "        nlp = None\n",
    "\n",
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"üîß Preprocessing tools initialized!\")"
   ]
  },
  {
  
 "cell_type": "markdown",
   "metadata": {
    "id": "task5"
   },
   "source": [
    "## Task 5: Text Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preprocessing_functions"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Basic text cleaning\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and lowercase (case folding)\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove user mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    \"\"\"Tokenization\"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"Remove stop words\"\"\"\n",
    "    return [token for token in tokens if token not in stop_words and len(token) > 2]\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    \"\"\"Stemming\"\"\"\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    \"\"\"Lemmatization\"\"\"\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def preprocess_text(text, use_stemming=True, use_lemmatization=False):\n",
    "    \"\"\"Complete text preprocessing pipeline\"\"\"\n",
    "    # Clean text\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = tokenize_text(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    \n",
    "    # Apply stemming or lemmatization\n",
    "    if use_stemming:\n",
    "        tokens = stem_tokens(tokens)\n",
    "    elif use_lemmatization:\n",
    "        tokens = lemmatize_tokens(tokens)\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "print(\"üîß Text preprocessing functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task6"
   },
   "source": [
    "## Task 6: Apply Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apply_preprocessing"
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to the text data\n",
    "if text_column in df.columns:\n",
    "    print(\"üîÑ Applying text preprocessing...\")\n",
    "    \n",
    "    # Create processed text column\n",
    "    df['processed_text'] = df[text_column].apply(lambda x: preprocess_text(x, use_stemming=True))\n",
    "    \n",
    "    # Show examples of original vs processed text\n",
    "    print(\"\\nüìù Example of text preprocessing:\")\n",
    "    for i in range(min(3, len(df))):\n",
    "        print(f\"\\nOriginal: {df[text_column].iloc[i][:100]}...\")\n",
    "        print(f\"Processed: {df['processed_text'].iloc[i][:100]}...\")\n",
    "    \n",
    "    # Remove empty processed texts\n",
    "    original_shape = df.shape\n",
    "    df = df[df['processed_text'].str.len() > 0]\n",
    "    print(f\"\\nüìä Dataset shape after preprocessing: {df.shape}\")\n",
    "    if original_shape[0] != df.shape[0]:\n",
    "        print(f\"   Removed {original_shape[0] - df.shape[0]} empty texts\")\n",
    "else:\n",
    "    print(\"‚ùå Please update the text_column variable with the correct column name\")\n",
    "    print(\"Available columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task7"
   },
   "source": [
    "## Task 7: Feature Extraction using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfidf_extraction"
   },
   "outputs": [],
   "source": [
    "# Import TF-IDF vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit to top 5000 features\n",
    "    min_df=2,          # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
    "    ngram_range=(1, 2) # Use unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit and transform the processed text\n",
    "if 'processed_text' in df.columns:\n",
    "    print(\"üîÑ Creating TF-IDF features...\")\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
    "    \n",
    "    print(f\"üìä TF-IDF matrix shape: {X_tfidf.shape}\")\n",
    "    print(f\"üìà Number of features: {len(tfidf_vectorizer.get_feature_names_out())}\")\n",
    "    \n",
    "    # Show top features\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    print(f\"\\nüî§ Sample features: {feature_names[:20]}\")\n",
    "    print(\"‚úÖ TF-IDF vectorization completed!\")\n",
    "else:\n",
    "    print(\"‚ùå Processed text not available. Please run the preprocessing step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task8"
   },
   "source": [
    "## Task 8: Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_training_data"
   },
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features and target variables\n",
    "if sentiment_column in df.columns and 'processed_text' in df.columns:\n",
    "    print(\"üîÑ Preparing training and testing data...\")\n",
    "    X = X_tfidf\n",
    "    y = df[sentiment_column]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Training set shape: {X_train.shape}\")\n",
    "    print(f\"üìä Testing set shape: {X_test.shape}\")\n",
    "    print(f\"\\nüìà Training set sentiment distribution:\")\n",
    "    print(y_train.value_counts())\n",
    "    print(f\"\\nüìà Testing set sentiment distribution:\")\n",
    "    print(y_test.value_counts())\n",
    "    print(\"‚úÖ Data preparation completed!\")\n",
    "else:\n",
    "    print(\"‚ùå Please ensure both sentiment and processed text columns are available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task9"
   },
   "source": [
    "## Task 9: Train MultinomialNB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "# Import MultinomialNB classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize and train MultinomialNB classifier\n",
    "nb_classifier = MultinomialNB(alpha=1.0)  # Laplace smoothing\n",
    "\n",
    "# Train the model\n",
    "print(\"ü§ñ Training MultinomialNB classifier...\")\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training completed!\")\n",
    "print(f\"üìä Number of classes: {len(nb_classifier.classes_)}\")\n",
    "print(f\"üè∑Ô∏è Classes: {nb_classifier.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task10"
   },
   "source": [
    "## Task 10: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_predictions"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "print(\"üîÆ Making predictions on test set...\")\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "y_pred_proba = nb_classifier.predict_proba(X_test)\n",
    "\n",
    "print(\"‚úÖ Predictions completed!\")\n",
    "print(f\"\\nüìä Predicted sentiment distribution:\")\n",
    "print(pd.Series(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task11"
   },
   "source": [
    "## Task 11: Model Evaluation - Accuracy and Basic Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "basic_metrics"
   },
   "outputs": [],
   "source": [
    "# Import evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate basic evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"üìä === MODEL PERFORMANCE METRICS ===\")\n",
    "print(f\"üéØ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"üéØ Precision (weighted): {precision:.4f}\")\n",
    "print(f\"üéØ Recall (weighted): {recall:.4f}\")\n",
    "print(f\"üéØ F1-Score (weighted): {f1:.4f}\")\n",
    "\n",
    "# Create a summary dataframe\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Score': [accuracy, precision, recall, f1]\n",
    "})\n",
    "\n",
    "print(\"\\nüìã Metrics Summary:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task12"
   },
   "source": [
    "## Task 12: Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "classification_report"
   },
   "outputs": [],
   "source": [
    "# Import classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate detailed classification report\n",
    "print(\"üìä === DETAILED CLASSIFICATION REPORT ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Convert to dataframe for better visualization\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "print(\"\\nüìã Classification Report as DataFrame:\")\n",
    "print(report_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task13"
   },
   "source": [
    "## Task 13: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "confusion_matrix"
   },
   "outputs": [],
   "source": [
    "# Import confusion matrix and seaborn for visualization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate and visualize confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = nb_classifier.classes_\n",
    "\n",
    "# Create confusion matrix visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title('üéØ Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix as dataframe\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(\"üìä Confusion Matrix:\")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task14"
   },
   "source": [
    "## Task 14: Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feature_analysis"
   },
   "outputs": [],
   "source": [
    "# Analyze most important features for each class\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "n_features = 10  # Top 10 features per class\n",
    "\n",
    "print(\"üîç === MOST IMPORTANT FEATURES BY CLASS ===\")\n",
    "for i, class_label in enumerate(nb_classifier.classes_):\n",
    "    # Get feature log probabilities for this class\n",
    "    feature_log_prob = nb_classifier.feature_log_prob_[i]\n",
    "    \n",
    "    # Get top features\n",
    "    top_features_idx = np.argsort(feature_log_prob)[-n_features:]\n",
    "    top_features = [(feature_names[idx], feature_log_prob[idx]) for idx in top_features_idx]\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è Class: {class_label}\")\n",
    "    for feature, prob in reversed(top_features):\n",
    "        print(f\"   {feature}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task15"
   },
   "source": [
    "## Task 15: Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "performance_viz"
   },
   "outputs": [],
   "source": [
    "# Create performance visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Metrics bar plot\n",
    "metrics_df.plot(x='Metric', y='Score', kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('üìä Model Performance Metrics')\n",
    "axes[0,0].set_ylabel('Score')\n",
    "axes[0,0].set_ylim(0, 1)\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "axes[0,0].legend().remove()\n",
    "\n",
    "# 2. Class-wise performance\n",
    "class_metrics = report_df.iloc[:-3, :3]  # Exclude avg rows and support column\n",
    "class_metrics.plot(kind='bar', ax=axes[0,1])\n",
    "axes[0,1].set_title('üìà Class-wise Performance')\n",
    "axes[0,1].set_ylabel('Score')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "axes[0,1].legend(['Precision', 'Recall', 'F1-Score'])\n",
    "\n",
    "# 3. Prediction distribution\n",
    "pred_dist = pd.Series(y_pred).value_counts()\n",
    "pred_dist.plot(kind='pie', ax=axes[1,0], autopct='%1.1f%%')\n",
    "axes[1,0].set_title('ü•ß Predicted Sentiment Distribution')\n",
    "axes[1,0].set_ylabel('')\n",
    "\n",
    "# 4. True vs Predicted comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'True': y_test.value_counts(),\n",
    "    'Predicted': pd.Series(y_pred).value_counts()\n",
    "})\n",
    "comparison_df.plot(kind='bar', ax=axes[1,1])\n",
    "axes[1,1].set_title('üìä True vs Predicted Distribution')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task16"
   },
   "source": [
    "## Task 16: Sample Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample_predictions"
   },
   "outputs": [],
   "source": [
    "# Analyze some sample predictions\n",
    "sample_indices = np.random.choice(X_test.shape[0], size=5, replace=False)\n",
    "\n",
    "print(\"üîç === SAMPLE PREDICTIONS ANALYSIS ===\")\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    true_label = y_test.iloc[idx]\n",
    "    pred_label = y_pred[idx]\n",
    "    pred_proba = y_pred_proba[idx]\n",
    "    \n",
    "    print(f\"\\nüìù Sample {i+1}:\")\n",
    "    print(f\"   True Label: {true_label}\")\n",
    "    print(f\"   Predicted Label: {pred_label}\")\n",
    "    print(f\"   Prediction Confidence: {max(pred_proba):.4f}\")\n",
    "    \n",
    "    # Show probabilities for all classes\n",
    "    for j, class_label in enumerate(nb_classifier.classes_):\n",
    "        print(f\"     P({class_label}): {pred_proba[j]:.4f}\")\n",
    "    \n",
    "    correct = '‚úÖ' if true_label == pred_label else '‚ùå'\n",
    "    print(f\"   Correct: {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "task17"
   },
   "source": [
    "## Task 17: Model Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_summary"
   },
   "outputs": [],
   "source": [
    "# Final model summary\n",
    "print(\"üéµ === MODEL SUMMARY ===\")\n",
    "print(f\"üìä Dataset: Spotify Sentiment Analysis\")\n",
    "print(f\"ü§ñ Algorithm: Multinomial Na√Øve Bayes\")\n",
    "print(f\"üìà Total samples: {len(df)}\")\n",
    "print(f\"üèãÔ∏è Training samples: {len(X_train)}\")\n",
    "print(f\"üß™ Testing samples: {len(X_test)}\")\n",
    "print(f\"üî§ Number of features: {X_tfidf.shape[1]}\")\n",
    "print(f\"üè∑Ô∏è Number of classes: {len(nb_classifier.classes_)}\")\n",
    "\n",
    "print(\"\\nüîß === PREPROCESSING TECHNIQUES APPLIED ===\")\n",
    "print(\"‚úÖ Tokenization\")\n",
    "print(\"‚úÖ Case folding (lowercase conversion)\")\n",
    "print(\"‚úÖ Punctuation removal\")\n",
    "print(\"‚úÖ Stop words removal\")\n",
    "print(\"‚úÖ Stemming\")\n",
    "print(\"‚úÖ TF-IDF Vectorization\")\n",
    "\n",
    "print(\"\\nüéØ === FINAL PERFORMANCE ===\")\n",
    "print(f\"üéØ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"üéØ Weighted F1-Score: {f1:.4f}\")\n",
    "print(f\"üéØ Weighted Precision: {precision:.4f}\")\n",
    "print(f\"üéØ Weighted Recall: {recall:.4f}\")\n",
    "\n",
    "print(\"\\nüí° === RECOMMENDATIONS ===\")\n",
    "if accuracy > 0.8:\n",
    "    print(\"‚úÖ Model shows good performance\")\n",
    "elif accuracy > 0.7:\n",
    "    print(\"‚ö†Ô∏è Model shows moderate performance - consider feature engineering\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Model needs improvement - try different preprocessing or algorithms\")\n",
    "\n",
    "print(\"\\nüéâ Analysis completed successfully!\")\n",
    "print(\"\\nüöÄ Great job on completing the Spotify sentiment analysis!\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"\\nüíæ Don't forget to save your results!\")\n",
    "    print(\"   File ‚Üí Download ‚Üí Download .ipynb\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}